%flow



\section{引入光流估计任务}

\paragraph{无监督光流估计}

光流网\cite{fischer2015flownet}出现不就, 无监督光流估计也随之出现\cite{Jason2016,Ren2016}, 常见方法与之前的\cite{Zhou2017}思路非常类似, 也是通过一种反向求解的自监督手段产生监督信号的方法, 只不过之前是要通过深度图$D_{t+1}$和位姿变换$T_{t->t+1}$反向求解前一帧的深度估计$\widehat{D_t}$, 这里则是使用$I_{t+1}$和前一帧的后向光流$F_t$传入空间变换网络STN\cite{Max2015}得到前一帧的图像估计$\widehat{I_t}$, 再将$I_{t+1}$与$\widehat{I_t}$的相似性度量作为损失项, 优化整体网络.


\begin{figure}[htbp]
	\centering
	
	\subfigure[\cite{Jason2016}中的无监督光流架构, 光流网来自\cite{fischer2015flownet}]{
		%\begin{minipage}[t]{0.25\linewidth}
		\centering
		\includegraphics[width=1\linewidth]{other/uflownet}
		%\caption{fig1}
		%	\end{minipage}
	}%
	
	\subfigure[\cite{Ren2016}中的无监督光流架构]{
		%	\begin{minipage}[t]{0.25\linewidth}
		\centering
		\includegraphics[width=1\linewidth]{other/uflownet2}
		%\caption{fig2}
		%	\end{minipage}%
	}%
	%这个回车键很重要 \quad也可以
	\caption{上述两个无监督光流架构在整体上基本一样, 都是传入$I_{t+1}$通过STN反向求解前一帧图像$\hat{I}_t$, 再将其与$I_t$的相似性度量来作为损失项}
	
\end{figure}

%STNand AAAI的套路

另外,\cite{Liu2019selflow}将噪声注入超像素以产生遮挡，并让一个模型引导另一个模型来学习遮挡像素的光流, 得到了目前结果最好的无监督光流方法. 

另外, 背景光流场信息(不含运动物体的光流)与相机自运动有极强的相关性. 

\paragraph{深度估计结合光流估计方法}

\cite{Zhou2017}中将运动估计引入来辅助解决深度估计问题, 而光流估与运动估计和深度估计都存在着极强的相关性.
%
\cite{Yin2018geonet}采用FlowNet,PoseNet辅助, 联合DepthNet一起训练. 这样可采用任何一对双向流预测中的一致性检查来处理遮挡和非朗伯表面

\begin{figure}[htbp]
	% caption放上面就会显示在图的上方，出现在下面就是出现在图的下方
	\begin{center}
		\includegraphics[width=0.9\linewidth]{other/pipeline}
		\caption{\cite{Yin2018geonet}的框架, 包括静态背景的结构重建部分,和运动物体定位部分}
		\label{fig:geonet}%label放在caption下面貌似才得行，要不然有问号
	\end{center}
\end{figure}

\cite{Zou2018dfnet}首次使用了光流网络FlowNet作为子网络, 并且联合PoseNet, DepthNet进行多任务学习\ref{fig:dfnet}, 并且在文中也花了一些篇幅阐述多任务学习的优势. 其主要贡献在于提出交叉任务的一致性损失来解决网络的训练, 而且在测试时三个子网络可以分别各自测试, 作者还通过kitti,make3d等大量数据集验证了联合学习的的优势.
%dfnet 网络结构图

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.9\linewidth]{other/eccv_Model_overview_camera.pdf}
	% \vspace{\figcapmargin}
	\caption{\textbf{\cite{Zou2018dfnet}中的无监督联合学习框架.}
		%
		整体框架主要包含三个部分: 
		%
		(1) 用来单帧图像深度估计的 \emph{Depth Net}; 
		%
		(2) 传入两相邻帧并得到相机自运动的\emph{Pose Net}; 
		%
		(3) 传入两相邻帧并得到密集光流场的 \emph{Flow Net} 
		. 
		%
		从两张图片 $\mathbf{I}_t$ 和 $\mathbf{I}_{t+1}$ 中,先分别得到深度, 6D 相机与运动, 还有密集光流. 
		% 
	}
	\label{fig:dfnet}
\end{figure}

%先将相邻帧$I_t, I_{t+1}$分别传入depthnet, 得到深度图$D_t, D_{t+1}$, 在联合posenet得到的6DOF相对位姿变化得到光流$F_{rigid}$ 这与\cite{Yin2018geonet}完全相同, 不同的是这里的$F_{rigid}$包含$t$时刻的前向光流$F_{t->t+1}$和$t+1$时刻的后向光流$F_{t+1->t}$.
%先将相邻帧$I_t, I_{t+1}$直接传入flownet得到前向光流和后向光流图;


文章的主要特色在于每次求光流场时会算出前一帧的后向光流和后一帧的前向光流, 使其通过一致性损失排除两幅图内的无效区域. 无效区域包含两部分, 一部分是因为视野变化导致有些区域在两幅图像并不都存在的地方; 另一部分是视野内的移动物体, 如车行人等物. 理想情况下, 有效区域应该只包含场景内的静态背景, 这能有效提高以此为参考的损失函数的性能.







