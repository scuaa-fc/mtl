\section{多任务系统中的任务平稳问题}


在之前的章节中，已经讨论过关于机场面安全方面的任务以及分类，机场场面安全任务主要分为以下三种视觉任务：检测任务、跟踪任务以及实例分割任务。在多任务系统中，任务自身之间的关联程度的高低对于多任务系统的性能具有至关重要的作用，即任务的关联度越高，对于多任务系统的提升具有更高的帮助，比如：现在的多任务系统在计算机视觉方面主要针对：语义分割、法向量估计、边缘检测等关联度较高的任务\cite{liu2019end}。虽然任务之间的关联度越高、对于提升多任务系统的系统具有主要的作用，但是任务之间的平衡也占着举足轻重的。

在现实世界中的学习过程，通常我们会更容易学习简单的知识，对于困难的知识，我们需要花费更多的时间去探索。作为灵长动物的人类可以根据任务的困难程度去规划不同难度的知识所需的时间以及精力。但是计算机暂时无法做到如同人这样的智能，只能根据预先设定好的策略为不同的任务分配不同的资源以便学习相应知识，而这资源分配策略的制订是及其困难的，主要体现如何判断在学习过程中，针对不同的应用级任务（如：机尾号识别、航空器跟踪以及跑道检测），什么时候应该分配多少的资源给哪些应用级任务用于学习知识。而在多任务系统学习过程中，损失函数主要体现了系统的资源分配，具体来讲就是反向传播过程中，每个任务的损失值所占的比例，这影响了每个任务梯度下降的尺度。

针对每个视觉任务来讲，多任务系统中任务之间的平衡问题是一致，即无论是检测任务、跟踪任务以及实例分割任务，都可采用一致的资源分配策略，也就是损失函数优化方法。本章节不讨论针对具体的应用级视觉任务的损失函数优化方法，因为相关研究是丰富的，且针对不同的应用级任务，一种优化方法可能是不合适的，本章节只讨论如何调节每个应用级任务的损失值在学习过程中所占的权重。相比于手动权重赋值，智能权重赋值方法是将其它因素（如：任务的不确定性）作为衡量标准，以作为权重调节的基础。


\subsection{手动赋权}


讨论权重赋值方法，则无法规避手动权重赋值法。手动权重赋值法主要是指在训练过程中，损失函数所占的权重是固定的，不会随着训练迭代的是次数的增加而逐渐增加, 即目标函数为${Loss}_{all}=\sum_{i=1}^{n}{w_i{Loss}_i}$，其中$w_i$为第i个任务的权重，${Loss}_i$为第i个任务的损失值。针对权重$w_i$的分配方法通常采用的是手动赋值的方法，如：通过大量的实验，调节每个应用级任务的权重，选择其中性能最优的权重分配。这种方法是简单粗暴的，且只适用于任务较少，如：2-3个任务的系统，对于大于3个的多任务系统来讲，为探索最优的权重分配策略是耗时、耗力的，也是及其不推荐的方法，如文献\cite{strezoski2019many}讨论了如何通过单个网络实现超20个任务，但是却没考虑任务之间的平衡。但是针对于一些具有强耦合性的多任务系统，这种权重赋值方法是可行的，如文献\cite{li2021transmission,sun2019robust}。在文献\cite{li2021transmission}中，对于无人机拍摄图片中的传输线进行检测以及分类，包含了两个任务：二值分割（是否为传输线）以及示例分割（对每条线进行编号），此两种任务具有高度耦合性，存在明显的递进关系。而文献\cite{li2021transmission}中的耦合性则更具有关联性，在空中加油中，对于drogue的内圈标志和外圈标志分别进行检测，而这两类目标的特征具有高度相似性。因此，多任务系统中，若应用级任务存在递进或者平行关系，同时目标特征具有高度一致性，则采用固定权重赋值法是可行的。在关于数据集方面的论文中\cite{yu2020bdd100k}以及讨论哪些任务可以用于共同学习时\cite{standley2020tasks}，无权重赋值也是一种公正的态度。除了简单的权重相加，添加正则项也有助于多任务系统的学习\cite{yang2020d3vo,kokkinos2017ubernet}。有意思的是如文献\cite{yin2020airport}则在机场检测任务的训练过程中，如IoU＞0.5，proposal box则分配位置损失，否则视为背景。


\subsection{智能赋权}

相比于手动权重赋值法，智能权重赋值法则不需要人为去设定每个任务所占的权重。通常情况下，此类方法都将提取任务的某些特性用于考量任务的损失权重。文献\cite{ruder2017overview}认为利用先验知识去判断任务之间关联性是具有积极意义的。

\subsubsection{同步学习}

\paragraph{任务平衡}

不同的任务的学习难度是不一致的，简单的任务更容易也更快学习，任务之间也存在竞争关心，因此合理的资源分配是极其必要的，即：相比于简单的任务而言，困难的任务需要更多的资源，任务之间的平衡就变得困难起来。文献\cite{guo2018dynamic}认为在训练过程中，熵是变化的，也是任务的学习难度是变化的，针对不同的迭代周期，任务的损失权重应该是变化的，如采用以下的方式对损失函数进行权重赋值：
\begin{eqnarray}
    \mathcal{L}_{DTP}\left(\cdot\right)=\mathcal{L}_{\mathrm{Total\ }}^\ast\left(\cdot\right)=\sum_{t=1}^{\left|T\right|} FL\left({\bar{\kappa}}_t;\gamma_t\right)\mathcal{L}_t^\ast\left(\cdot\right)
\end{eqnarray}
其中$FL\left({\bar{\kappa}}_t;\gamma_t\right)$为任务t的学习难度。文献\cite{kendall2018multi}则将不确定性作为任务损失权重的考虑因素，作者认为损失权重应该依赖于任务的度量尺度以及噪声大小，因此提出基于同方差不确定性的高斯似然最大化对损失权重进行赋值，
\begin{eqnarray}
    \mathcal{L}\left(\mathbf{W},\sigma_1,\sigma_2\right)=\\
    \nonumber
    \frac{1}{2\sigma_1^2}\mathcal{L}_1\left(\mathbf{W}\right)+ \frac{1}{\sigma_2^2}\mathcal{L}_2\left(\mathbf{W}\right)+ \log{\sigma_1}+\log{\sigma_2}    
\end{eqnarray}
。文献\cite{zheng2019pyramidal}则将任务梯度的变化率作为考虑因素，计算指数移动平均线$k_\tau^t=\alpha L_\tau^t+\left(1-\alpha\right)k_{\tau-1}^t$，其中$L_\tau^t$为任务t在$\tau$次迭代后的平均精度，可以获得$p_\tau^t=\frac{min\left\{k_\tau^t,k_{\tau-1}^t\right\}}{k_{\tau-1}^t}$，该值越大说明进入局部最小值的概率最大，降低对简单任务的关注$L=\sum_{t\in\left\{id,tp\right\}}\left(p_\tau^t-1\right)^\gamma\log{\left(p_\tau^t\right)L_\tau^t}$。文献\cite{liu2019end}也梯度相对下降率的方法来对损失权重进行赋值，如
\begin{eqnarray}
    \lambda_k(t)=\frac{K\exp\left(w_k(t-1)/T\right)}{\sum_{i}\exp\left(w_i(t-1)/T\right)}\\
    w_k(t-1)=\frac{\mathcal{L}_k(t-1)}{\mathcal{L}_k(t-2)}
\end{eqnarray}
多任务系统训练过程中，标签具有举足轻重的作用，因此文献\cite{wu2020understanding}对于标签噪声（如弱监督标签）时，则提升其它任务的权重，以降低标签噪声的影响。文献\cite{chen2018gradnorm}为了追求任务之间的平衡，将所有的任务规范到一个范围内，对于训练过快或者梯度变化幅度大的任务进行惩罚，$L(t)=\sum w_i(t)L_i(t)$。以上方法的差异并不是很明显\cite{gong2019comparison}。文献\cite{sener2018multi,lin2019pareto}都将多任务问题转化为一个Pareto优化问题，找到一个最优解以实现任务之间的平衡。在多任务强化学习中，也需要通过调节每个任务对agent的贡献，来实现动态平衡\cite{hessel2019multi,schaul2019ray}，也有使具有冲突的任务的梯度相互正交，尽量避免任务之间的相互干扰\cite{yu2020gradient}。



大多数方法考虑了任务之间的关联性，但是不同任务梯度之间的关联性是否对多任务系统的性能是否有影响呢？这是一个有意思的问题，因此文献\cite{sinha2018gradient}探索了在反向传播过程中，不同的任务的损失梯度之间的差异性是否对多任务系统的训练有影响，答案是肯定的。因此该方法通过学习梯度之间的差异性，去消除这种梯度差异性对多任务训练的影响。文献\cite{song2021attention}主动学习每个任务的权重，只反向传播损耗较大的样本\cite{hrivastava2016training}，从而在整个训练过程中共同对任务和样本进行优先级排序。


\paragraph{主任务辅助}


增添辅助任务来实现主任务的性能最大化或者效率也是多任务的一个重要用途\cite{liebel2018auxiliary,du2018adapting}，如：一些简单的辅助任务并不会造成资源的更多使用，但是有助于提升多任务系统的性能。在这类问题中，需要注意的是辅助任务与主任务之间的主次之别，也就是主任务一定要占据主导地位，这与通俗上的多任务系统是有差别的，通常的多任务系统是要避免单个任务具有主导性。文\cite{du2018adapting}中就描述了增加辅助任务来提升主任务性能时，需要判断辅助任务何时对主任务是有益，何时是有害，在每次迭代过程中，目标优化函数为：
\begin{eqnarray}
    {\arg{min}}_{\lambda^{(t)}}\mathcal{L}\left({\theta}^{(t)}-\alpha\nabla_{\theta}\left(\mathcal{L}+\lambda^{(t)}\mathcal{L}_{\mathrm{aux\ }}\right),{\phi}^{(t)}-\alpha\nabla_{{\phi}}\mathcal{L}\right)
\end{eqnarray}
与辅助任务具有相似之处的是中间任务，通过添加中间监督的方式，实现对主任务性能的提升\cite{xu2018pad}。


\subsubsection{异步学习}


早期的部分研究，将多任务学习看成一种依次学习过程，不要求多任务的同时完成，而是采用循环的方式，每次迭代只对一个任务进行训练\cite{pentina2015curriculum,maninis2019attentive,li2017self,rosenbaum2017routing}，这种训练方法的好处在于可以一定程度上避免任务之间的相互干扰（一次只学习一个任务），也可以保证系统资源的充分利用，使用逐步优化的方式实现多任务系统整体性能的提升，这就避免了损失权重的不合理导致任务之间的不平衡，即任务的损失权重为$\mathbf{w}^{(i)}=\left[w_1^{(i)},\ldots,w_{n_i}^{(i)}\right]\in[0,1]ni$。在文献\cite{li2017self}中，作者让多任务系统根据实例和任务的复杂程度对学习顺序进行排列，然后按照从简单到困难的顺序来对任务进行学习。本质来讲，这是同步学习与异步学习的差别，文献\cite{doersch2017multi}中的方法采用了异步学习的思想，针对每个任务，单独使用一个worker（GPU）去学习，当单个任务的损失值累积到一定程度之后，则进行反馈传播，不需要与其它任务形成同步。Continual learning也是多任务学习中的一个应用，不同于多任务系统中注重与任务之间的平衡，continual learning更讲究任务之间的不干扰，针对先后学习的任务，尽可能地使不同任务的梯度空间处于正交状态，从而使两个任务之间的干扰尽可能最小\cite{suteu2019regularizing,farajtabar2020orthogonal}。





\subsection{优化策略}

\subsubsection{任务难度评估以及资源分配}


机场场面多任务中任务的难度不同将导致任务训练速度以及梯度调节幅度的不一致，对于困难的任务需要倾注更多的资源，因此需要对任务难度进行有效评估。考虑到机场场面任务具有高度耦合性，这里推荐梯度+时间差异估计法对任务难度进行评估。计算每个任务k当前迭代周期i中的梯度与上一迭代周期梯度之比$p_i^k=\frac{L_i^k}{L_{i-1}^k}$，并对所有任务进行归一化得到权重$\lambda_i^k=\frac{exp\left(p_i^k\right)}{\sum_{j} e x p\left(p_j^k\right)}$。计算每个任计算每个任务k当前迭代周期i中的训练时长与上一迭代周期的训练时长之比$t_i^k=\frac{T_i^k}{T_{i-1}^k}$，并对所有任务进行归一化得到权重$\beta_i^k=\frac{exp\left(t_i^k\right)}{\sum_{j} e x p\left(t_j^k\right)}$。则在单次迭代过程中，每个任务的损失权重为$\frac{\lambda_i^k+\beta_i^k}{2}$。


\subsubsection{共享信息可靠性评估}

机场场面安全中的任务之间的交互，这里主要针对于具有低耦合性的多任务之间。这些任务之间的大多数信息是不利于对方的，因此需要可采用正交策略，将不同的任务的梯度看成梯度空间的基向量，在第i次迭代过程中，将任务m,k之间的关联度${cos}^2\left(L_i^k,L_i^m\right)$作为学习对象，并赋予动态权重，如：$L_i^{all}=\omega_k\left(t\right)L_i^k+\omega_m\left(t\right)L_i^m+\omega_{cos}\left(t\right){cos}^2\left(L_i^k,L_i^m\right)$。


\subsection{总结}

针对机场场面多任务，仍然以任务的平衡为主，根据任务的不同、采用不同的特征共享策略，损失函数的优化策略也具有差异性。在场景检测类任务集中，主要以“分类+关键点检测”任务这两大视觉任务为主，不同任务之间利用信息传递的方式，实现性能的提升，该过程中，损失函数的主要作用实现各种任务之间的平衡。对于机场场面安全来讲，所有任务的重要性是相同的，具有代表性的应用级机场场面任务为目标检测+跟踪以及飞机的位姿估计，第一个类型属于视觉任务具有高度相似性的，第二种类型属于视觉任务之间没有明显的相似性的。因此，机场场面多任务学习面临两个主要的挑战：1）对于耦合性高的多任务，如何实现任务之间的平衡，即如何评估任务的难度以分配合理的资源；2）针对耦合性低的多任务，则需要减少信息之间的交互。
