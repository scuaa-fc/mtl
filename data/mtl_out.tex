%strategy

\section{视觉下多任务学习外的范式关系}
\label{sec:mtl_out}

MTL 与机器学习中的其他学习范式相关, 包括迁移学习 \cite{yzdp20}、多标签学习 \cite{zz14} 和多输出回归等. 在第\ref{sec:mtl_in}章中， 我们讨论了多任务学习内，任务的关系，本章则讨论多任务学习范式与其他学习范式之间的关系。

\subsection{迁移学习范式}

MTL 的设置类似于迁移学习的设置, 但有显着差异. 
在 MTL 中, 不同任务之间没有区别, 目标是提高所有任务的性能. 
然而, 迁移学习是在源任务的帮助下提高目标任务的性能, 因此目标任务比源任务起着更重要的作用. 总之, MTL 对所有任务一视同仁, 但在迁移学习中, 目标任务最受关注. 
从知识流的角度来看, 迁移学习中的知识转移流是从源任务到目标任务, 但在多任务学习中, 任何一对任务之间都有知识共享的流. 具体来说，迁移学习是一种可以理解为持续学习的策略\cite{pkpkw19}, 其中对任务的学习是依次而来, 一个一个地学习任务, 而MTL是一起学习多个任务. 在多标签学习和多输出回归中, 每个数据点都与多个标签相关联, 这些标签可以是分类的或数字的. 如果我们将所有可能的标签都视为一个任务, 那么多标签学习和多输出回归在某种意义上可以看作是多任务学习的一个特例, 其中不同的任务在训练和训练期间总是共享相同的数据. 



\subsection{监督学习范式}
在大多数应用中, 标记数据的收集成本很高, 但未标记的数据却很丰富. 因此在一些 MTL 应用中, 每个任务的训练数据集由标记数据和未标记数据组成, 因此我们希望利用未标记数据中包含的有用信息来进一步提高监督学习任务的性能.

在机器学习中, 半监督学习和主动学习是利用未标记数据的两种方式, 但方式不同. 
半监督学习旨在利用未标记数据中包含的几何信息, 而主动学习则选择具有代表性的未标记数据来查询预言机, 希望尽可能少地增加标记成本. 
因此, 半监督学习和主动学习可以与 MTL 结合, 产生三种新的学习范式, 包括半监督多任务学习 \cite{llc07,lllsc09,zy09}、多任务主动学习 \cite{rthr08,amg14,  ft15} 和半监督多任务主动学习 \cite{llc09a}. 
具体而言, \cite{llc07,lllsc09} 中提出了一种半监督多任务分类模型, 使用随机游走来利用每个任务中的未标记数据, 然后通过宽松的狄利克雷过程对多个任务进行聚类. 
在 \cite{zy09} 中, 提出了一种用于回归任务的半监督多任务高斯过程, 其中不同的任务通过所有任务的高斯过程中的内核参数的超先验相关联, 将未标记的数据合并到设计中每个任务中的核函数, 以在相应的功能空间中实现平滑. 与这些半监督多任务方法不同, 多任务主动学习为多任务学习者自适应地选择信息丰富的未标记数据, 因此选择标准是核心研究问题. 
Richard等人.  \cite{rthr08} 相信要选择的数据实例应该为一组任务提供尽可能多的信息, 而不是只有一个任务, 因此他们提出了两种用于多任务主动学习的协议. 
在\cite{amg14} 中, 预期误差减少用作标准, 其中每个任务都由监督的潜在狄利克雷分配模型建模. 受平衡开发和探索之间权衡的多臂老虎机的启发, \cite{ft15} 中提出了一种选择策略, 以考虑基于轨迹范数正则化的多任务学习器的风险和相应的置信度边界. 
在\cite{pl17}中, 提出的泛化界限用于从多个未标记的任务中选择一个子集来获取标签, 以提高所有任务的泛化性能. 对于半监督多任务主动学习, Li 等人.  
\cite{llc09a} 提出了一个模型, 使用 Fisher 信息作为标准来选择未标记的数据以获取它们的标签, 其中半监督多任务分类模型 \cite{llc07,lllsc09} 作为每个任务的分类器. 


\subsection{无监督学习范式}
MTL 不仅在监督学习任务中实现了性能提升, 而且在聚类等无监督学习任务中也实现了性能提升.
在 \cite{zz10} 中, 提出了一种基于单任务 Bregman 聚类的多任务 Bregman 聚类方法, 通过使用推土机距离来最小化任何一对任务之间在聚类中心方面的距离, 然后在 \cite{zz13,  zzl15a}, \cite{zz10} 的改进版本及其内核扩展被提出, 通过在单任务和多任务 Bregman 聚类之间选择更好的一个来避免 \cite{zz10} 中的正则化器造成的负面影响. 在 \cite{glh11} 中, 提出了一种多任务内核 $k$-means 方法, 它通过任意一对任务之间的 MMD 和有助于识别平滑内核空间的拉普拉斯正则化来学习内核矩阵. 在 \cite{zhang15c} 中, 提出的两种多任务聚类方法是 MTFL 和 MTRL 方法的扩展, 将标签视为要学习的聚类指标. 在\cite{wwlcw15} 中, MTL 的原理通过捕获数据实例之间的相关性被纳入子空间聚类. 在\cite{zzl16}中, 提出了一种属于基于实例的MTL的多任务聚类方法, 以在不同任务之间共享数据实例. 在\cite{ymyns15}中, 提出了一种多任务谱聚类算法, 该算法可以通过线性函数处理样本外问题来学习聚类分配, 通过实现任务间的特征选择$\ell_{2,1}$正则化 \cite{zlzjw17}.  \cite{zzll18b} 建议识别任务集群结构并一起学习任务关系. 

\subsection{强化学习范式}
强化学习 (RL) 是机器学习中一个很有前途的领域, 并且在许多应用程序中表现出卓越的性能, 例如游戏（例如 Atari 和围棋）和机器人技术.  MTL 可以帮助提高强化学习的性能, 从而实现多任务强化学习 (MRL). 
具体来说, 在 \cite{wfrt07} 中, 任务解决一系列马尔可夫决策过程 (MDP), 使用分层贝叶斯无限混合模型对 MDP 上的分布进行建模, 并且对于每个新的 MDP, 以前学习的分布用作信息事先的. 
在 \cite{llc09b} 中, 引入了区域化策略表示来表征每个任务中代理的行为, 并将 Dirichlet 过程放置在跨多个任务的区域化策略表示上, 以对任务进行聚类. 
在\cite{lg10}中, 每个任务都使用高斯过程时间差值函数模型, 分层贝叶斯方法是对不同任务中值函数的分布进行建模. 

% \subsection{稀疏学习范式}
% 卡兰德列洛等人.  \cite{clr14} 假设不同任务中的值函数的参数向量是联合稀疏的, 然后使用 $\ell_{2,1}$ 正则化和 MTFL 方法扩展 MTFS 方法以一起学习多个任务中的值函数.
% 在 \cite{akl17} 中, 提出了一种将每个子任务与模块化子策略相关联的模型, 以从策略草图中学习, 该模型用命名子任务序列注释任务, 并提供有关任务之间高级结构关系的信息. 
% 在 \cite{ser17} 中, 提出了一个多任务线性可解 MDP, 其任务基础矩阵包含所有任务共享的组件任务库, 用于维护任务的并行分布式表示, 每个任务都使代理能够利用宏动作同时进行. 
% 在\cite{bbrw19} 中, 基于注意力的多任务深度强化学习模型可以自动将任务分组到状态级粒度的子网络中. 
% 在\cite{vnnbkttl19} 中, 引入了一个共享经验框架, 以使用特定于任务的奖励来识别定义为共享区域的相似部分, 这些部分可以指导任务策略的经验共享. 
% 在 \cite{ignsbw20} 中, 多任务软选项学习, 一种基于规划作为推理的分层框架, 通过共享先验进行正则化, 以避免训练不稳定, 并允许在不忘记学习策略的情况下微调新任务的选项. 
% 压缩和蒸馏的概念已被纳入 MRL, 如 \cite{pbs16,rcgdkpmkh16,opahv17,tbcqkhhp17}. 
% 例如, 在 \cite{pbs16} 中, 提议的 Actor-Mimic 方法结合了深度强化学习和模型压缩技术来训练一个可以学习为多个任务采取行动的策略网络. 
% 在\cite{rcgdkpmkh16} 中, 提出了一种策略蒸馏方法, 不仅可以训练一个有效的网络来学习代理的策略, 还可以将多个特定于任务的策略合并为一个策略. 
% 在\cite{opahv17}中, 通过将分散的单任务策略提炼为跨多个任务的统一策略来解决部分可观察性下的多任务多智能体强化学习问题. 
% 在 \cite{tbcqkhhp17} 中, 每个任务都有自己的策略, 该策略被限制为接近由蒸馏训练的共享策略. 
% MRL 中的一些作品 \cite{bbt17,sr17,sjhr18,esmsmwdf18,tkb18,lbkh19} 侧重于在线和分布式设置. 
% 具体来说, 在 \cite{bbt17} 中, 设计了一个分布式 MRL 框架, 将其建模为普遍共识的实例, 并开发了一个高效的分散式求解器. 
% 在 \cite{sr17,sjhr18} 中, 通过主动采样更难的任务, 在不需要专家监督的在线设置中学习多个目标导向的任务. 
% 在\cite{esmsmwdf18} 中, 开发了一个分布式代理, 不仅可以在单机训练中更有效地使用资源, 而且可以在不牺牲数据效率或资源利用率的情况下扩展到数千台机器. 
% \cite{tkb18} 从变分推理的角度制定了 MRL, 它提出了一种具有二次收敛保证的新型分布式求解器. 
% 在\cite{lbkh19}中, 提出了一种在线学习算法来动态组合不同的辅助任务, 这些辅助任务提供梯度方向以加速主要强化学习任务的训练. 
% 一些著作研究了 MRL 的理论基础. 
% 例如, 在 \cite{dtbrp20} 中, 任务之间的共享表示通过理论保证进行分析, 以突出共享表示的条件, 并将近似值迭代的有限时间范围扩展到多任务设置. 

% 此外, 还有一些工作可以设计新颖的 MRL 方法. 例如, 在 \cite{sxs18} 中, 提出了一个 MRL 框架来训练代理使用分层策略来决定何时使用以前学习的策略以及何时使用时间语法学习新技能, 帮助代理学习复杂的时间依赖性.
% \cite{hsecsh19} 研究多个顺序决策任务的并行学习问题, 并提出自动调整每个任务对代理更新的贡献, 使所有任务对学习动态具有可比的影响. 
% 在\cite{gpapagm20}中, 提出了一种用于多任务深度强化学习的自监督表示学习算法, 以基于未来观察的多步预测表示来捕获有关环境动态的结构化信息. 

\subsection{联邦学习范式}

联邦学习本质上是一种分布式机器学习技术，或机器学习框架。
联邦学习的目标是在保证数据隐私安全及合法合规的基础上，实现共同建模，提升AI模型的效果。
联邦学习最早在 2016 年由谷歌提出\cite{konevcny2016federated}，原本用于解决安卓手机终端用户在本地更新模型的问题。

对于一些数据或者特殊场景下的应用来说，其敏感程度并不能允许模型采用一般的训练，而将模型简单的交付过去。
例如在人脸识别应用中，我们并不希望自己的人脸数据直接传输到服务商的存储器上并来训练模型，另外，在机场安全应用中，有些军事机场规模较小数据量少，飞机型号敏感，此类数据更是关系到国家安全，对待的态度尤其需要慎重。
以上应用，就涉及到多个同样任务的联合训练，即联邦学习。

把每个参与共同建模的企业称为参与方，根据多参与方之间数据分布的不同，把联邦学习分为三类：横向联邦学习、纵向联邦学习和联邦迁移学习\footnote{\url{https://zhuanlan.zhihu.com/p/79284686?utm_source=wechat_session}}。
横向联邦学习的本质是样本的联合，适用于参与者间业态相同但触达客户不同，即特征重叠多，用户重叠少时的场景，比如不同地区的银行间，他们的业务相似（特征相似），但用户不同（样本不同）。
在传统的机器学习建模中，通常是把模型训练需要的数据集合到一个数据中心然后再训练模型，之后预测。在横向联邦学习中，可以看作是基于样本的分布式模型训练，分发全部数据到不同的机器，每台机器从服务器下载模型，然后利用本地数据训练模型，之后返回给服务器需要更新的参数；服务器聚合各机器上的返回的参数，更新模型，再把最新的模型反馈到每台机器。

在这个过程中，每台机器下都是相同且完整的模型，且机器之间不交流不依赖，在预测时每台机器也可以独立预测，可以把这个过程看作成基于样本的分布式模型训练。谷歌最初就是采用横向联邦的方式解决安卓手机终端用户在本地更新模型的问题的
纵向联邦学习的本质是特征的联合，适用于用户重叠多，特征重叠少的场景，比如同一地区的商超和银行，他们触达的用户都为该地区的居民（样本相同），但业务不同（特征不同）。
当参与者间特征和样本重叠都很少时可以考虑使用联邦迁移学习，如不同地区的银行和商超间的联合。主要适用于以深度神经网络为基模型的场景。

在以上联邦学习中，要针对采取的应用特点而应用不同策略。




% %多视图学习
% \subsection{多视图学习}
% 多视图学习假设每个数据点都与多组特征相关联, 其中每组特征对应一个视图, 它通常利用多个视图中包含的信息进行监督或半监督学习任务. 多任务多视图学习将多视图学习扩展到 MTL 设置, 其中每个任务都是多视图学习问题. 具体来说, 在\cite{hl11}中, 针对多任务多视图分类问题提出了一种基于图的方法. 在一个任务中, 每个视图都被强制要求与其他视图和标签保持一致, 而不同的任务期望对它们共享的视图有相似的预测, 使视图成为构建任务相关性的桥梁. 在\cite{zh12}中, 正则化的MTL方法\cite{emp05}和MTRL方法都应用于不同任务的每个视图, 并且任务中的不同视图期望在未标记数据上达成一致. 与研究多任务多视图分类问题的\cite{hl11,zh12}不同, 在\cite{zzl15b,zzll16}中, 提出了两种多任务多视图聚类方法, 这两种方法都考虑了三个因素：视图任务聚类, 对任务中的每个视图进行聚类, 视图关系学习, 最大限度地减少任务中视图之间的分歧, 以及低秩结构学习, 旨在学习公共视图下不同任务的共享子空间. 这两种方法的区别在于, 第一种方法对非负数据采用二部图共聚类方法, 而另一种采用半非负矩阵三分解对一般数据进行聚类. 在 \cite{zlz16} 中, 提出了一种多标签多视图算法, 不仅可以通过 $\ell_{2,1}$ 正则化学习共同特征, 还可以通过 Frobenius 范数识别无用的视图. 在多任务多视图学习中, 每个任务通常都提供有标记和未标记的数据, 因此这种范式也可以看作是另一种利用未标记信息进行 MTL 的方式.  \cite{zch19} 中提出了一种深度多任务多视图模型来融合基于十字绣网络的所有视图. 


\subsection{多任务与其他范式关系总结}

多任务学习相关的范式有很多，但并不是每个都能较好的应用在视觉任务中，尤其是场景监测类任务集的衍生应用中，例如机场安全、人脸识别等。

在迁移学习范式下，多数目标任务的调优，又或者称为目标任务迁移，是在一个确定目标域上进行的，但是模型的初始化训练任务则极为固定，一般都是在ImageNet\cite{ImageNet}上进行图像分类任务，以此作为初始化。此种方法可行性也有充足的工作来证明\cite{hendrycks2019using,he2019rethinking}, 而且在场景监测类任务中图像分类也是作为基础任务，特征空间应该与其余任务高度重合。但是，对于一些场景感知类任务，使用图像分类作为基础任务进行初始化虽能起到一定程度，但是任务之间的距离相对来说并不是那么近，因此针对场景感知类任务集，以场景感知类任务在合适的数据集上初始化\cite{wang2020geometric}无疑能更快的使得模型在目标任务中收敛，因此对目标域能指向性灵活变换的源域开发是一个理想的方法。

根据数据的条件以及现有的资源，模型训练应该灵活调整是否我有监督、半监督还是无监督。例如在机场环境由虚拟工具搭建的情况下，通过有监督训练一个初始化模型就是一个合适的选择。在应用落地时，根据不同机场的环境以及规模等，可以将预训练模型在迁移学习的调优过程中更改监督方法。

由于数据的敏感以及信息安全等要求，联邦学习被提出。这中学习范式尤其适用于对安全领域要求较高的应用例如人脸识别以及机场安全。针对不同的规模以及性质的机场，联合了联邦学习范式的多任务学习模型应该以信息安全训练为前提，解决机场的运营安全问题。

